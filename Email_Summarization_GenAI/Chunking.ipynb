{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "495c4641",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "from langchain_openai import AzureOpenAIEmbeddings, AzureChatOpenAI\n",
    "from langchain.text_splitter import  RecursiveCharacterTextSplitter,  CharacterTextSplitter\n",
    "\n",
    "from langchain_community.document_loaders import JSONLoader, DirectoryLoader\n",
    "from langchain_community.document_loaders import UnstructuredExcelLoader,  UnstructuredPowerPointLoader, Docx2txtLoader, PyPDFLoader,  UnstructuredWordDocumentLoader, TextLoader, UnstructuredFileLoader\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from langchain.retrievers.merger_retriever import MergerRetriever\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter\n",
    "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c2c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c406e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_type = \"azure\"\n",
    "open_ai_api_version = \"2023-05-15\"\n",
    "open_ai_api_key = \"open_ai_api_key\"\n",
    "open_ai_api_key = open_ai_api_key \n",
    "open_ai_endpoint = \"open_ai_endpoint\" # base\n",
    "embeddings_model = \"janus-text-embedding-ada-002\"\n",
    "gpt_deployment_4 = \"janus-gpt-4\"\n",
    "gpt_deployment_35 = \"janus-gpt-35-turbo\"\n",
    "gpt_deployment_35_16=\"janus-gpt-35-turbo-16k\"\n",
    "embeddings_model = \"janus-text-embedding-ada-002\"\n",
    "vector_store_endpoint = \"vector_store_endpoint\"\n",
    "vector_store_key = \"vector_store_key\"\n",
    "vector_index_name = \"vector_index_name\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c7ea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_name = gpt_deployment_35\n",
    "llm_model = AzureChatOpenAI(deployment_name=deployment_name, openai_api_key =open_ai_api_key, azure_endpoint = open_ai_endpoint, openai_api_version = open_ai_api_version, temperature=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf686e3",
   "metadata": {},
   "source": [
    "### Initiating the embedding model and connection to Azure ai search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a2a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=embeddings_model,\n",
    "    openai_api_version=open_ai_api_version,\n",
    "    azure_endpoint = open_ai_endpoint,\n",
    "    openai_api_key = open_ai_api_key\n",
    ")\n",
    "\n",
    "vector_store = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_endpoint ,\n",
    "    azure_search_key=vector_store_key,\n",
    "    index_name=vector_index_name,\n",
    "    embedding_function=embeddings.embed_query\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c30f28",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DirectoryLoader('your_fike_path', glob=\"**/*.txt\", loader_cls=TextLoader, loader_kwargs={'autodetect_encoding': True})\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7efd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[1].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdebf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b56521",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.as_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85990db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,\n",
    "    SearchField,  \n",
    "    VectorSearch,\n",
    "    VectorSearchProfile,\n",
    "    HnswAlgorithmConfiguration\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733be4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client = SearchClient(vector_store_endpoint, vector_index_name, vector_store_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646203fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity_score_threshold\", search_kwargs={\"score_threshold\": 0.8}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.invoke(\"Where is my package. I can't find it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0968b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"where is my parcel. I have not received yet.I am mad\"\n",
    "retriever1 = vector_store.similarity_search_with_relevance_scores(query = query, k = 1, kwargs ='0.8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a84adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.similarity_search_with_relevance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(embeddings,breakpoint_threshold_type=\"standard_deviation\")\n",
    "# docs = text_splitter.create_documents(documents[0].page_content)\n",
    "doc = []\n",
    "for i in range(len(documents)):\n",
    "    doc.append(documents[i].page_content)\n",
    "docs = text_splitter.create_documents(doc)\n",
    "# print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16d2471",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter.create_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14d3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_documents(search_client):\n",
    "    results = search_client.search(search_text=\"*\", top=1000)  # Adjust the top value as needed\n",
    "    documents = list(results)\n",
    "    return documents\n",
    "\n",
    "def find_duplicates(documents):\n",
    "    seen = set()\n",
    "    duplicates = []\n",
    "    for doc in documents:\n",
    "        if doc['id'] in seen:\n",
    "            duplicates.append(doc)\n",
    "        else:\n",
    "            seen.add(doc['id'])\n",
    "    return duplicates\n",
    "\n",
    "def delete_documents(client, documents):\n",
    "    ids_to_delete = [doc['id'] for doc in documents]\n",
    "    client.delete_documents(*ids_to_delete)\n",
    "    print(f\"Deleted {len(ids_to_delete)} documents.\")\n",
    "\n",
    "# Retrieve documents and find duplicates\n",
    "documents = get_documents(search_client)\n",
    "duplicates = find_duplicates(documents)\n",
    "print(f\"Found {len(duplicates)} duplicates.\")\n",
    "\n",
    "# Delete duplicate documents\n",
    "delete_documents(search_client, duplicates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faebec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all documents\n",
    "results = search_client.get_documents()\n",
    "\n",
    "# Create a dictionary to hold unique documents\n",
    "unique_docs = {}\n",
    "\n",
    "# Loop through the results\n",
    "for result in results:\n",
    "    # Use a unique field (like 'id') to check for duplicates\n",
    "    id = result[\"id\"]\n",
    "    if id not in unique_docs:\n",
    "        # If the document is unique, add it to the dictionary\n",
    "        unique_docs[id] = result\n",
    "    else:\n",
    "        # If the document is a duplicate, delete it\n",
    "        search_client.delete_documents({\"id\": id})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
